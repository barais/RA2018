Diversity is acknowledged as a crucial element for resilience, sustainability and increased wealth in many domains such as  sociology, economy and ecology. 
Yet, despite the large body of theoretical and experimental science that emphasizes the need to conserve high levels of diversity in complex systems, the limited amount of diversity in software-intensive systems is a major issue. 
This  is particularly critical as these systems integrate multiple concerns, are connected to the physical world, run eternally and are open to other services and to users.
Here we present our latest observational and technical results about (i) observations of software diversity mainly through browser fingerprinting, and (ii) software testing to study and assess the validity of software. 

\subsubsection{Privacy and Security}

\paragraph{FP-STALKER: Tracking Browser Fingerprint Evolutions}

Browser fingerprinting has emerged as a technique to track users without their consent. Unlike cookies, fingerprinting is a stateless technique that does not store any information on devices, but instead exploits unique combinations of attributes handed over freely by browsers. The uniqueness of fingerprints allows them to be used for identification. However, browser fingerprints change over time and the effectiveness of tracking users over longer durations has not been properly addressed. In this work~\cite{vastel:hal-01652021}, we show that browser fingerprints tend to change frequently—from every few hours to days—due to, for example, software updates or configuration changes. Yet, despite these frequent changes, we show that browser fingerprints can still be linked, thus enabling long-term tracking. FP-STALKER is an approach to link browser fingerprint evolutions. It compares fingerprints to determine if they originate from the same browser. We created two variants of FP-STALKER, a rule-based variant that is faster, and a hybrid variant that exploits machine learning to boost accuracy. To evaluate FP-STALKER, we conduct an empirical study using 98,598 fingerprints we collected from 1,905 distinct browser instances. We compare our algorithm with the state of the art and show that, on average, we can track browsers for 54.48 days, and 26\% of browsers can be tracked for more than 100 days. 
 

\paragraph{Hiding in the Crowd: an Analysis of the Effectiveness of Browser Fingerprinting at Large Scale}

Browser fingerprinting is a stateless technique, which consists in collecting a wide range of data about a device through browser APIs. Past studies have demonstrated that modern devices present so much diversity that fingerprints can be exploited to identify and track users online. With this work~\cite{gomezboix:hal-01718234}, we want to evaluate if browser fingerprinting is still effective at uniquely identifying a large group of users when analyzing millions of fingerprints over a few months.We analyze 2,067,942 browser fingerprints collected from one of the top 15 French websites. The observations made on this novel dataset shed a newlight on the ever-growing browser fingerprinting domain. The key insight is that the percentage of unique fingerprints in this dataset is much lower than what was reported in the past: only 33.6\% of fingerprints are unique by opposition to over 80\% in previous studies. We show that non-unique fingerprints tend to be fragile. If some features of the fingerprint change, it is very probable that the fingerprint will become unique. We also confirm that the current evolution of web technologies is benefiting users’ privacy significantly as the removal of plugins brings down substantively the rate of unique desktop machines.


\paragraph{User Controlled Trust and Security Level of Web Real-Time Communications}

In this work~\cite{corre:tel-01943728}, we propose three main contributions. In our first contribution we study the WebRTC identity architecture and more particularly its integration with existing authentication delegation protocols. This integration has not been studied yet. To fill this gap, we implement components of the WebRTC identity architecture and comment on the issues encountered in the process. We then study this specification from a privacy perspective an identify new privacy considerations related to the
central position of identity provider. In our second contribution, we aim at giving more control to users. To this end,
we extend the WebRTC specification to allow identity parameters  negotiation.  We  then  propose  a  web  API  allowing users to choose their identity provider in order to authenticate on a third-party website. We validate our propositions by presenting prototype implementations. Finally, in our third contribution, we propose a trust and security model of a WebRTC session to help non-expert users to better understand the security of their WebRTC session. Our proposed model integrates in a single metric the security parameters used in the session establishment, the encryption parameters for the media streams, and trust in
actors of the communication setup as defined by the user. We conduct a preliminary study on the comprehension of our model to validate our approach.


\subsubsection{Software Testing}

\paragraph{A Comprehensive Study of Pseudo-tested Methods}

Pseudo-tested methods are defined as follows: they are covered by the test suite, yet no test case fails when the method body is removed, i.e., when all the effects of this method are suppressed. This intriguing concept was coined in 2016, by Niedermayr and colleagues~\footcite{niedermayr2016}, who showed that such methods are systematically present, even in well-tested projects with high statement coverage. This work presents a novel analysis of pseudo-tested methods~\cite{veraperez:hal-01867423}. First, we run a replication of Niedermayr's study with 28K+ methods, enhancing its external validity thanks to the use of new tools and new study subjects. Second, we perform a systematic characterization of these methods, both quantitatively and qualitatively with an extensive manual analysis of 101 pseudo-tested methods. The first part of the study confirms Niedermayr's results: pseudo-tested methods exist in all our subjects. Our in-depth characterization of pseudo-tested methods leads to two key insights: pseudo-tested methods are significantly less tested than the other methods; yet, for most of them, the developers would not pay the testing price to fix this situation. This calls for future work on targeted test generation to specify those pseudo-tested methods without spending developer time. 

This work uses Descartes is a tool that implements extreme mutation operators and aims at finding pseudo-tested methods in Java projects~\cite{veraperez:hal-01870976}. It leverages the efficient transformation and runtime features of PITest.


\paragraph{Automatic Test Improvement with DSpot: a Study with Ten Mature Open-Source Projects}

In the literature, there is a rather clear segregation between manually written tests by developers and automatically generated ones. In this work~\cite{danglot:hal-01923575}, we explore a third solution: to automatically improve existing test cases written by developers. We present the concept, design and implementation of a system called DSpot, that takes developer-written test cases as input (JUnit tests in Java) and synthesizes improved versions of them as output. Those test improvements are given back to developers as patches or pull requests, that can be directly integrated in the main branch of the test code base. We have evaluated DSpot in a deep, systematic manner over 40 real-world unit test classes from 10 notable and open-source software projects. We have amplified all test methods from those 40 unit test classes. In 26/40 cases, DSpot is able to automatically improve the test under study, by triggering new behaviors and adding new valuable assertions. Next, for ten projects under consideration, we have proposed a test improvement automatically synthesized by DSpot to the lead developers. In total, 13/19 proposed test improvements were accepted by the developers and merged into the main code base. This shows that DSpot is capable of automatically improving unit-tests in real-world, large scale Java software.


\paragraph{Multimorphic Testing}

The functional correctness of a software application is, of course, a prime concern, but other issues such as its execution time, precision , or energy consumption might also be important in some contexts. Systematically testing these quantitative properties is still extremely difficult, in particular, because there exists no method to tell the developer whether such a test set is "good enough" or even whether a test set is better than another one. This work~\cite{temple:hal-01730163} proposes a new method, called Multimorphic testing, to assess the relative effectiveness of a test suite for revealing performance variations of a software system. By analogy with mutation testing, our core idea is to vary software parameters, and to check whether it makes any difference on the outcome of the tests: i.e. are some tests able to " kill " bad morphs (configurations)? Our method can be used to evaluate the quality of a test suite with respect to a quantitative property of interest, such as execution time or computation accuracy. 





\paragraph{User Interface Design Smell: Automatic Detection and Refactoring of Blob Listeners}

User Interfaces (UIs) intensively rely on event-driven programming: widgets send UI events, which capture users' interactions, to dedicated objects called controllers. Controllers use several UI listeners that handle these events to produce UI commands. In this work~\cite{blouin:hal-01499106}, we reveal the presence of design smells in the code that describes and controls UIs. We then demonstrate that specific code analyses are necessary to analyze and refactor UI code, because of its coupling with the rest of the code. We conducted an empirical study on four large Java Swing and SWT open-source software systems: Eclipse, JabRef, ArgouML, and FreeCol. We study to what extent the number of UI commands that a UI listener can produce has an impact on the change-and fault-proneness of the UI listener code. We develop a static code analysis for detecting UI commands in the code. We identify a new type of design smell, called Blob listener that characterizes UI listeners that can produce more than two UI commands. We propose a systematic static code analysis procedure that searches for Blob listener that we implement in InspectorGuidget. We conducted experiments on the four software systems for which we manually identified 53 instances of Blob listener. The results exhibit a precision of 81.25 \% and a recall of 98.11 \%. We then developed a semi-automatically and behavior-preserving refactoring process to remove Blob listeners. 49.06 \% of the Blob listeners were automatically refactored. Patches for JabRef, and FreeCol have been accepted and merged. Discussions with developers of the four software systems assess the relevance of the Blob listener.




%\paragraph{Software diversification}  
%*******DIVERSITY*******%      

%Our work on software diversification explores various ways of adding randomness in program executions: state perturbations that preserve functional correctness \cite{danglot:hal-01378523}; randomizing of web APIs to mitigate browser fingeprinting \cite{laperdrix:hal-01527580}. 

%Can the execution of software be perturbed without breaking the correctness of the output?
%In this work \cite{danglot:hal-01378523}, we devise a protocol to answer this question from a novel perspective.
%In an experimental study, we observe that many perturbations do not break the correctness in ten subject programs. 
%We call this phenomenon ``correctness attraction''.
%The uniqueness of this protocol is that it considers a systematic exploration of the perturbation space as well as perfect oracles to determine the correctness of the output. 
%To this extent, our findings on the stability of software under execution perturbations have a level of validity that has never been reported before in the scarce related work.
%A qualitative manual analysis enables us to set up the first taxonomy ever of the reasons behind correctness attraction.

%The rich programming interfaces (APIs) provided by web browsers can be diverted to collect a browser fingerprint. A small number of queries on these interfaces are sufficient to build a fingerprint that is statistically unique and very stable over time. Consequently, the fingerprint can be used to track users. Our work \cite{laperdrix:hal-01527580} aims at mitigating the risk of browser fingerprinting for users privacy by 'breaking' the stability of a fingerprint over time. We add randomness in the computation of selected browser functions, in order to have them deliver slightly different answers for each browsing session. Randomization is possible thanks to the following properties of browsers implementations: (i) some functions have a nondeterministic specification, but a deterministic implementation ; (ii) multimedia functions can be slightly altered without deteriorating user's perception. We present FPRandom, a modified version of Firefox that adds randomness to mitigate the most recent fingerprinting algorithms, namely canvas fingerprinting, AudioContext fingerprinting and the unmasking of browsers through the order of JavaScript properties. We evaluate the effectiveness of FPRandom by testing it against known fingerprinting tests. We also conduct a user study and evaluate the performance overhead of randomization to determine the impact on the user experience. 

%The other aspect in the area of software diversity  is about the statistical analysis of browser fingerprinting on a large industrial dataset \cite{laperdrix:tel-01621257,gomezboix:hal-01611101}. 


%\paragraph{Software testing}  
%*******TESTING*******%      
%Generative software development has paved the way for the creation of multiple code generators and compilers that serve as a basis for automatically generating code to a broad range of software and hardware platforms. With full automatic code generation, the user is able to easily and rapidly synthetize software artifacts for various software platforms. In addition, modern generators (i.e., C compilers) become highly configurable, offering numerous configuration options that the user can use to easily customize the generated code for the target hardware platform.
%In this context, it is crucial to verify the correct behaviour of code generators. Numerous approaches have been proposed to verify the functional outcome of generated code but few of them evaluate the non-functional properties of automatically generated code, namely the performance and resource usage properties.
%The thesis of Mohamed Boussaa \cite{boussaa:tel-01598821} has addressed this limitation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%