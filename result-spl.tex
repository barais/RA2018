% We select three main contributions for this DiverSE's research axis.
% Two contributions are in the field of variability model synthesis, while the third one is in the field of variability testing.



    
    
    
	% We hope to gather more and more data (open data like Wikipedia) and offer innovative services on top of our canonical format.
	% Papers have been notably published at FSE'13, ASE'13 and ASE'14 (ASE and FSE are leading conferences in software engineering), SPLC'15 (SPLC is a leading conference in variability). %%% TODO JSS.
%	\end{description}


% \end{description}

\paragraph{Variability and testing.}
Many approaches for testing configurable software systems start from the same assumption: it is impossible to test all configurations. This motivated the definition of variability-aware abstractions and sampling techniques to cope with large configuration spaces. Yet, there is no theoretical barrier that prevents the exhaustive testing of all configurations by simply enumerating them, if the effort required to do so remains acceptable. Not only this: we believe there is lots to be learned by systematically and exhaustively testing a configurable system. We report on the first ever endeavor to test all possible configurations of an industry-strength, open source configurable software system, JHipster, a popular code generator for web applications. We built a testing scaffold for the 26,000+ configurations of JHipster using a cluster of 80 machines during 4 nights for a total of 4,376 hours (182 days) CPU time. We find that 35.70\% configurations fail and we identify the feature interactions that cause the errors. We show that sampling testing strategies (like dissimilarity and 2-wise) (1) are more effective to find faults than the 12 default configurations used in the JHipster continuous integration; (2) can be too costly and exceed the available testing budget. We cross this quantitative analysis with the qualitative assessment of JHipster's lead developers.
Publication at Empirical Software Engineering: ~\cite{halin:hal-01829928}
See also, in the rest of the report, the work on \emph{Multimorphic Testing} that actually relies on variability techniques. 
% preliminary effort on JHipster~\cite{halin:hal-01468084}, \url{https://arxiv.org/abs/1710.07980} \url{https://github.com/axel-halin/Thesis-JHipster/}


\paragraph{Variability and teaching.}

Software Product Line (SPL) engineering has emerged to provide the means to efficiently model, produce, and maintain multiple similar software variants, exploiting their common properties, and managing their variabilities (differences). With over two decades of existence, the community of SPL researchers and practitioners is thriving as can be attested by the extensive research output and the numerous successful industrial projects. Education has a key role to support the next generation of practitioners to build highly complex, variability-intensive systems. Yet, it is unclear how the concepts of variability and SPLs are taught, what are the possible missing gaps and difficulties faced, what are the benefits, or what is the material available. Also, it remains unclear whether scholars teach what is actually needed by industry. We report on three initiatives we have conducted with scholars, educators, industry practitioners, and students to further understand the connection between SPLs and education, i.e., an online survey on teaching SPLs we performed with 35 scholars, another survey on learning SPLs we conducted with 25 students, as well as two workshops held at the International Software Product Line Conference in 2014 and 2015 with both researchers and industry practitioners participating. We build upon the two surveys and the workshops to derive recommendations for educators to continue improving the state of practice of teaching SPLs, aimed at both individual educators as well as the wider community. Finally, we are developing and maintaining a repository for teaching SPLs and variability.
Publication at SPLC (journal first)~\cite{acher:hal-01829933}, workshop SPLTea'18 \url{http://spltea.irisa.fr/} and repository: \url{https://teaching.variability.io}

%\paragraph{Variability and constraint solving.}  
%Array constraints are essential for handling data structures in automated reasoning and software verification. Unfortunately, the use of a typical finite domain (FD) solver based on local consistency-based filtering has strong limitations when constraints on indexes are combined with constraints on array elements and size. This work proposes an efficient and complete FD-solving technique for extended constraints over (possibly unbounded) arrays. We describe a simple but particularly powerful transformation for building an equisatisfiable formula that can be efficiently solved using standard FD reasoning over arrays, even in the unbounded case. Experiments show that the proposed solver significantly outperforms FD solvers, and successfully competes with the best SMT-solvers~\cite{plazar:hal-01545557}.
% This work is not directly related to variability and SPL. 
% But it contributes to DiverSE's attempts to connect artificial intelligence techniques to software variability engineering, in which constraint solving or machine learning are typically applied. 

\paragraph{Variability and machine learning}
%\begin{description}
%	\item[Contribution.] 
We propose the use of a machine learning approach to infer variability constraints
from an oracle that is able to assess whether a given configuration is correct.
We propose an automated procedure to generate configurations, classify them according to the oracle, and synthesize cross-tree constraints. Specifically, based on an oracle (e.g. a runtime test) that tells us whether a given configuration meets the requirements (e.g. speed or memory footprint), we leverage machine learning to retrofit the acquired knowledge into a variability model of the system that can be used to automatically specialize the configurable system. We validate our approach on a set of well-known configurable software systems (Apache server, x264, etc.) 
Our results show that, for many different kinds of objectives and performance qualities, the approach has interesting accuracy, precision and recall after a learning stage based on a relative small number of random samples.
Publications: Temple et al. \emph{Towards Adversarial Configurations for Software Product Lines} \url{https://arxiv.org/abs/1805.12021}, VaryLaTeX~\cite{acher:hal-01659161} a variability and learning-based tool to generate relevant paper variants written in \latex. 

\emph{TUXML (Tux is the mascotte of the Linux Kernel while ML stands for statistical machine learning)}. The goal of TuxML  is to predict properties of Linux Kernel configurations (e.g., does the kernel compile? what's its size? does it boot?). The Linux Kernel provides near 15000 configuration options: there is an infinity of different kernels. As we cannot compile, measure, and observe all combinations of options (aka configurations), we're trying to learn Linux kernel properties out of a sample of configurations. The TuxML project is developing tools, mainly based on Docker and Python, to massively compile and gather data about thousand of configuration kernels~\url{https://github.com/TuxML/}.

In general, we are currently exploring the use of machine learning for variability-intensive systems in the context of VaryVary ANR project \url{https://varyvary.github.io}.




%\subsection{Reverse engineering variability}
%
%We have developed automated techniques and a comprehensive environment for synthesizing feature models from various kinds of artefacts (e.g. propositional formula, dependency graph, FMs or product comparison matrices). Specifically we have elaborated a support (through ranking lists, clusters, and logical heuristics) for choosing a sound and meaningful hierarchy. 
%We have performed an empirical evaluation on hundreds of feature models, coming from the SPLOT repository and Wikipedia.
%% We have provided evidence that a fully automated synthesis (i.e., without any user intervention) is likely to produce models far from the ground truths. 
%We have showed that a hybrid approach mixing logical and ontological techniques
%outperforms state-of-the-art solutions (Empirical Software Engineering journal in 2016~\cite{becan:hal-01096969}). 
%
%
%% We have also considered numerical information and feature \emph{attributes} so that we are now capable of synthesizing attributed feature models from product descriptions~\cite{becan:hal-01178454}. 
%
%% Besides, we have developed techniques for reverse engineering variability in generators and configurators (e.g., video generators)~\cite{becan:hal-01104797}. 
%% We have identified new research directions for protecting variability~\cite{acher:hal-01234342} mainly due to the fact reverse engineering techniques (previously presented) are effective .
%
%
%\subsection{Product comparison matrices}
%
%Product Comparison Matrices (PCMs) constitute a rich source of data for comparing a set of related and competing products over numerous features. PCMs can be seen as a formalism for modeling a family of products, including variability information.
%Despite their apparent simplicity, PCMs contain heterogeneous, ambiguous, uncontrolled and partial information that hinders their efficient exploitations. 
%We have formalized PCMs through model-based automated techniques and developed additional tooling to support the edition and re-engineering of PCMs~\cite{becan:hal-01058440}. 20 participants used our editor to evaluate our PCM metamodel and automated transformations. The empirical results over 75 PCMs from Wikipedia show that (1) a significant proportion of the formalization of PCMs can be automated: 93.11\% of the 30061 cells are correctly formalized; (2) the rest of the formalization can be realized by using the editor and mapping cells to existing concepts of the metamodel. 
%%
% % The ASE'2014 paper opens avenues for engaging a community in the mining, re-engineering, edition, and exploitation of PCMs that now abound on the Internet.
%We have launched an open, collaborative initiative towards this direction \url{http://www.opencompare.org}
%
%Another axis is the mining of PCMs since (1) the manual elaboration of PCMs has limitations (2) numerous sources of information can be combined and are amenable to PCMs. We have developed MatrixMiner a tool for automatically
%synthesizing PCMs from a set of product descriptions written in natural language~\cite{JSSbennasr}. %%% TODO JSS
%MatrixMiner is capable of identifying and organizing
%features and values in a PCM despite the informality and
%absence of structure in the textual descriptions of products. 
%More information is available online: \url{http://matrix-miner.variability.io}